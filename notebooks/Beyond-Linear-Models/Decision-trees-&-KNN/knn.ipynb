{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1080fad",
   "metadata": {},
   "source": [
    "# KNN-Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "241f7f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train(X_train, y_train):\n",
    "    '''trains the K-NN classifier; i.e. storage of training data'''\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64ecb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes two samples x and y and computes the euclidean distance\n",
    "euclidean = lambda x,y : np.sqrt(np.sum((x-y)**2))\n",
    "\n",
    "def calculate_distance(X_new, X_train):\n",
    "  ''' Calculates distance between new sample and stored training samples'''\n",
    "\n",
    "  distances = []\n",
    "\n",
    "  for i in range(len(X_train)):\n",
    "      distances.append(euclidean(X_new,X_train[i,:]))\n",
    "  return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5097a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(y_train, distances, k):\n",
    "  near_neigh_index = np.argsort(distances)[:k] # Find indices of k nearest neighbors\n",
    "  neigh_labels = y_train[near_neigh_index]  # labels of k nearest neighbors\n",
    "\n",
    "  return neigh_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b216f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(X_train, y_train, X_test, k):\n",
    "  '''K-NN classifier : Trains and then predicts label of test set\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  X_train: Numpy.array, shape(n,m)\n",
    "      training feature vector\n",
    "  y_train: Numpy.array, shape(n,)\n",
    "      training target vector\n",
    "  X_test: Numpy.array, shape(z,m)\n",
    "      Data to be classified\n",
    "  k: int\n",
    "      Number of neighbors to take into account\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  predictions: Numpy.array, shape(z,)\n",
    "      predicted labels of X_test\n",
    "  '''\n",
    "\n",
    "  train(X_train, y_train) # Training phase\n",
    "\n",
    "  predictions = []\n",
    "\n",
    "  for i in range(len(X_test)): # Prediction phase\n",
    "    neigh_dist = calculate_distance(X_test[i,:], X_train)\n",
    "    k_labels = predict_labels(y_train, neigh_dist, k)\n",
    "    predictions.append(np.argmax(np.bincount(k_labels)))\n",
    "\n",
    "  return np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d71da",
   "metadata": {},
   "source": [
    "## Performing knn classifier with iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc75f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_iris, y_iris = load_iris(return_X_y = True) # Loading the iris dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_iris, y_iris, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e687140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions of training set\n",
    "y_train_pred = knn_classifier(X_train, y_train, X_train, 3)\n",
    "\n",
    "# Predictions of test set\n",
    "y_test_pred = knn_classifier(X_train, y_train, X_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3407f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t------------------training set------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.95      0.97      0.96        36\n",
      "           2       0.97      0.95      0.96        37\n",
      "\n",
      "    accuracy                           0.97       105\n",
      "   macro avg       0.97      0.97      0.97       105\n",
      "weighted avg       0.97      0.97      0.97       105\n",
      "\n",
      "\t--------------------test set--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      0.93      0.96        14\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Performance evaluation\n",
    "print('\\t------------------training set------------------')\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print('\\t--------------------test set--------------------')\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39b9331",
   "metadata": {},
   "source": [
    "- performs exceptionally with accuracy of 97% on training set, and 96% on test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5c9592",
   "metadata": {},
   "source": [
    "## KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02408940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Knnregression():\n",
    "\n",
    "  def __init__(self, k):\n",
    "\n",
    "    self.k = k\n",
    "\n",
    "  def fit(self, X_train, y_train):\n",
    "\n",
    "    self.X_train = X_train\n",
    "    self.y_train = y_train\n",
    "\n",
    "  def _calculate_euc_dist_mat(self, X_test):\n",
    "\n",
    "    a = np.sum(self.X_train**2, axis=1).reshape(-1,1) # Reshaping for proper euclidean matrix.\n",
    "    b_T = np.sum(X_test**2, axis=1)\n",
    "    W = -2 * np.dot(self.X_train,X_test.T)\n",
    "    euc_mat = np.sqrt(a + b_T + W + 1e-10) # Adding small value to avoid warning.\n",
    "\n",
    "    return euc_mat\n",
    "\n",
    "  def predict(self, X_test):\n",
    "\n",
    "    self.predictions = []\n",
    "\n",
    "    dist_mat = self._calculate_euc_dist_mat(X_test)\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "      distance = dist_mat[:,i] # Taking ith column of distance matrix\n",
    "      near_neigh_index = np.argsort(distance)[:self.k]\n",
    "      near_neigh_labels = self.y_train[near_neigh_index]\n",
    "\n",
    "      self.predictions.append(np.mean(near_neigh_labels)) # Aggregation\n",
    "\n",
    "    return np.array(self.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4834bec",
   "metadata": {},
   "source": [
    "### Performing KNN on California housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c799ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.53966842 0.78431373 0.0435123  ... 0.00149943 0.5674814  0.21115538]\n",
      " [0.53802706 0.39215686 0.03822395 ... 0.00114074 0.565356   0.21215139]\n",
      " [0.46602805 1.         0.05275646 ... 0.00169796 0.5642933  0.21015936]\n",
      " ...\n",
      " [0.08276438 0.31372549 0.03090386 ... 0.0013144  0.73219979 0.31175299]\n",
      " [0.09429525 0.33333333 0.03178269 ... 0.0011515  0.73219979 0.30179283]\n",
      " [0.13025338 0.29411765 0.03125246 ... 0.00154886 0.72582359 0.30976096]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "X_scaled = MinMaxScaler().fit_transform(X)    # KNN needs to feature scaled before modelling for regression because of dependency on distance fxn\n",
    "\n",
    "print(X_scaled)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a72ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_reg = Knnregression(k=4)\n",
    "knn_reg.fit(X_train, y_train)\n",
    "\n",
    "knn_y_train_pred = knn_reg.predict(X_train)\n",
    "knn_y_test_pred = knn_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc75f9b1",
   "metadata": {},
   "source": [
    "### Comparing knn regression with classic linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "350e5872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN, Training MSE: 0.24\n",
      "KNN, Test MSE: 0.42\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "knn_train_error = mean_squared_error(y_train, knn_y_train_pred)\n",
    "knn_test_error = mean_squared_error(y_test, knn_y_test_pred)\n",
    "\n",
    "print(f'KNN, Training MSE: {knn_train_error:.2f}')\n",
    "print(f'KNN, Test MSE: {knn_test_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f650a2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression, Training MSE: 0.52\n",
      "Linear Regression, Test MSE: 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "lin_y_train_pred = lin_reg.predict(X_train)\n",
    "lin_y_test_pred = lin_reg.predict(X_test)\n",
    "\n",
    "lin_train_error = mean_squared_error(y_train, lin_y_train_pred)\n",
    "lin_test_error = mean_squared_error(y_test, lin_y_test_pred)\n",
    "\n",
    "print(f'Linear Regression, Training MSE: {lin_train_error:.2f}')\n",
    "print(f'Linear Regression, Test MSE: {lin_test_error:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a17673a",
   "metadata": {},
   "source": [
    "- The MSE errors for K-NN regression and linear regression model are around the same range, with slightly better performance of K-NN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab693a8a",
   "metadata": {},
   "source": [
    "## Searching nearest neighbors\n",
    "\n",
    "### Brute force method using manhattan distance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e76b764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 11, 3, 9, 10, 2, 3]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_offices_loc = [(6,12), (3,7), (10,10), (8,4), (15,2), (12,11), (14,10)]\n",
    "your_loc = (12,9)\n",
    "\n",
    "# Find distance between points\n",
    "distances=[]\n",
    "for i in range(len(post_offices_loc)):\n",
    "    distances.append(abs((your_loc[0] - post_offices_loc[i][0])) + abs(your_loc[1] - post_offices_loc[i][1]))\n",
    "    \n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a6c2495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_indexes_min_value(l):\n",
    "    min_value = min(l)\n",
    "    if l.count(min_value) > 1:\n",
    "        return [i for i, x in enumerate(l) if x == min(l)]\n",
    "    else:\n",
    "        return l.index(min(l))\n",
    "    \n",
    "location = get_indexes_min_value(distances)\n",
    "post_offices_loc[location]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a17db47",
   "metadata": {},
   "source": [
    "### KD tree for nearest neighbor search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7fab75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5488135  0.71518937]\n",
      " [0.60276338 0.54488318]\n",
      " [0.4236548  0.64589411]\n",
      " [0.43758721 0.891773  ]\n",
      " [0.96366276 0.38344152]\n",
      " [0.79172504 0.52889492]\n",
      " [0.56804456 0.92559664]\n",
      " [0.07103606 0.0871293 ]\n",
      " [0.0202184  0.83261985]\n",
      " [0.77815675 0.87001215]]\n",
      "\n",
      "\n",
      "[[0 2 1]]\n",
      "[[0.         0.14306129 0.1786471 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.random_sample((10, 2))  # 10 points in 3 dimensions\n",
    "print(X)\n",
    "print(\"\\n\")\n",
    "tree = KDTree(X, leaf_size=2)\n",
    "\n",
    "dist, ind = tree.query(X[:1], k=3)                \n",
    "print(ind)  # indices of 3 closest neighbors\n",
    "print(dist)  # distances to 3 closest neighbors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
